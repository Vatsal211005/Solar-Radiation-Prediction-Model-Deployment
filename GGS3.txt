import streamlit as st
import pandas as pd
import numpy as np
import folium
from streamlit_folium import st_folium
import joblib
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns

def clamp(value, min_val, max_val):
    """Ensure a value is within the specified min and max range."""
    return max(min_val, min(max_val, value))

# Set page configuration
st.set_page_config(
    page_title="Saudi Arabia Renewable Energy Atlas",
    page_icon="☀️",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS for styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E5631;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #1E5631;
        margin-bottom: 1rem;
    }
    .map-container {
        border-radius: 10px;
        border: 1px solid #ddd;
        padding: 1px;
    }
    .stButton button {
        background-color: #1E5631;
        color: white;
    }
    .info-box {
        background-color: #f0f8ff;
        border-radius: 5px;
        padding: 10px;
        border-left: 5px solid #1E5631;
    }
</style>
""", unsafe_allow_html=True)

# Function to load dataset
@st.cache_data
def load_dataset():
    df = pd.read_csv("dataset.csv")  # Update with actual path
    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y %H:%M')
    return df

# Function to load trained model
@st.cache_resource
def load_model():
    model_path = r"C:\Users\Dell\Desktop\model\nishantmodel.pkl"
    try:
        model = joblib.load(model_path)
        return model
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

# Load dataset and model
dataset = load_dataset()
model = load_model()

# Get all numerical columns dynamically
numerical_cols = dataset.select_dtypes(include=[np.number]).columns.tolist()
exclude_cols = ['Latitude', 'Longitude']
numerical_cols = [col for col in numerical_cols if col not in exclude_cols]

# Title and description
st.markdown("<h1 class='main-header'>Saudi Arabia Renewable Energy Atlas</h1>", unsafe_allow_html=True)

# Main content with only Map View, Data Analysis, and Prediction tabs
tab1, tab2, tab5 = st.tabs(["Map View", "Data Analysis", "Prediction"])

with tab1:
    st.markdown("<h2 class='sub-header'>Solar Resource Map</h2>", unsafe_allow_html=True)
    
    m = folium.Map(
        location=[24.0, 45.0],
        zoom_start=6,
        tiles="CartoDB positron"
    )
    
    if dataset is not None:
        for _, row in dataset.iterrows():
            popup_text = [row['Station_Name']]
            for col in numerical_cols:
                try:
                    value = float(row[col])
                    popup_text.append(f"{col}: {value:.2f}")
                except (ValueError, TypeError):
                    popup_text.append(f"{col}: N/A")
            
            folium.Marker(
                location=[row['Latitude'], row['Longitude']],
                popup="<br>".join(popup_text),
                icon=folium.Icon(color="orange", icon="sun", prefix="fa")
            ).add_to(m)
    
    legend_html = """
    <div style="position: fixed; bottom: 50px; left: 50px; width: 150px; height: 160px; 
    background-color: white; border:2px solid grey; z-index:9999; padding:10px;
    border-radius:5px; font-size: 14px;">
    <p><strong>Legend</strong></p>
    <div style="background-color:#d73027; width:20px; height:15px; display:inline-block;"></div> High<br>
    <div style="background-color:#fc8d59; width:20px; height:15px; display:inline-block;"></div> Medium-High<br>
    <div style="background-color:#fee090; width:20px; height:15px; display:inline-block;"></div> Medium<br>
    <div style="background-color:#e0f3f8; width:20px; height:15px; display:inline-block;"></div> Low-Medium<br>
    <div style="background-color:#91bfdb; width:20px; height:15px; display:inline-block;"></div> Low
    </div>
    """
    m.get_root().html.add_child(folium.Element(legend_html))
    
    st.markdown('<div class="map-container">', unsafe_allow_html=True)
    st_folium(m, width=1000, height=600, returned_objects=[])
    st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown("<h3 class='sub-header'>Station Data</h3>", unsafe_allow_html=True)
    st.markdown("<div class='info-box'>Select a station to view detailed information.</div>", unsafe_allow_html=True)
    
    selected_station = st.selectbox(
        "Select Station",
        options=dataset['Station_Name'].unique().tolist(),
        index=0
    )
    
    station_data = dataset[dataset['Station_Name'] == selected_station].iloc[0]
    
    st.markdown("### Station Details")
    st.markdown(f"**Site Name:** {selected_station}")
    st.markdown(f"**Longitude:** {station_data['Longitude']}")
    st.markdown(f"**Latitude:** {station_data['Latitude']}")
    
    st.markdown("<h3 class='sub-header'>Monthly Resource Data</h3>", unsafe_allow_html=True)
    selected_params = st.multiselect(
        "Select Parameters to Display",
        options=numerical_cols,
        default=['GHI (Wh/m2)', 'DNI (Wh/m2)'] if 'GHI (Wh/m2)' in numerical_cols else numerical_cols[:2]
    )
    
    station_data = dataset[dataset['Station_Name'] == selected_station]
    monthly_data = station_data.groupby(station_data['Date'].dt.month)[numerical_cols].mean()
    
    months = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
    chart_data = pd.DataFrame({"Month": months})
    for param in selected_params:
        if param in monthly_data.columns:
            chart_data[param] = monthly_data[param].values
    
    fig = px.bar(
        chart_data,
        x="Month",
        y=selected_params,
        barmode="group",
        title=f"Monthly Data at {selected_station}",
        color_discrete_sequence=px.colors.qualitative.Dark24
    )
    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.markdown("<h2 class='sub-header'>Data Analysis</h2>", unsafe_allow_html=True)
    
    if dataset is None:
        st.error("No dataset loaded. Please check your data source.")
        st.stop()
    
    try:
        numerical_cols = dataset.select_dtypes(include=[np.number]).columns.tolist()
        exclude_cols = ['Latitude', 'Longitude']
        numerical_cols = [col for col in numerical_cols if col not in exclude_cols]
    except Exception as e:
        st.error(f"Error detecting numerical columns: {e}")
        numerical_cols = []
    
    if not numerical_cols:
        st.warning("No numerical columns found for analysis.")
        st.stop()
    
    st.markdown("### Environmental Parameters Heatmap")
    try:
        default_heatmap_param = 'GHI (Wh/m2)' if 'GHI (Wh/m2)' in numerical_cols else numerical_cols[0]
        heatmap_param = st.selectbox(
            "Select Parameter for Heatmap",
            options=numerical_cols,
            index=numerical_cols.index(default_heatmap_param)
        )
    except Exception as e:
        st.error(f"Error in heatmap parameter selection: {e}")
        heatmap_param = numerical_cols[0]
    
    try:
        heat_data = []
        for _, row in dataset.iterrows():
            try:
                lat = float(row['Latitude'])  # Ensure numeric
                lon = float(row['Longitude'])  # Ensure numeric
                value = float(row[heatmap_param])  # Ensure numeric
                if pd.isna(lat) or pd.isna(lon) or pd.isna(value):
                    continue  # Skip rows with NaN values
                heat_data.append([lat, lon, value])
            except (ValueError, TypeError) as e:
                st.write(f"Skipping row due to invalid data: Latitude={row['Latitude']}, Longitude={row['Longitude']}, {heatmap_param}={row[heatmap_param]}")
                continue
        
        if heat_data:
            heat_map = folium.Map(location=[24.0, 45.0], zoom_start=6, tiles="CartoDB positron")
            folium.plugins.HeatMap(
                heat_data,
                radius=15,
                blur=20,
                gradient={0.4: 'blue', 0.65: 'yellow', 1: 'red'}
            ).add_to(heat_map)
            st_folium(heat_map, width=1000, height=400)
        else:
            st.warning(f"No valid data points found for {heatmap_param}. Check your dataset for non-numeric or missing values.")
    except Exception as e:
        st.error(f"Error creating heatmap: {e}")
    
    st.markdown("### Station Comparison")
    try:
        selected_stations = st.multiselect(
            "Select Stations to Compare",
            options=dataset['Station_Name'].unique().tolist(),
            default=[dataset['Station_Name'].iloc[0]]
        )
        
        compare_params = st.multiselect(
            "Select Parameters to Compare",
            options=numerical_cols,
            default=numerical_cols[:3]
        )
        
        station_data = dataset[dataset['Station_Name'].isin(selected_stations)]
        
        for param in compare_params:
            fig = px.line(
                station_data,
                x='Date',
                y=param,
                color='Station_Name',
                title=f'{param} Comparison Across Stations',
                labels={'value': param}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    except Exception as e:
        st.error(f"Error in station comparison: {e}")
    
    st.markdown("### Correlation Analysis")
    try:
        corr_data = dataset[numerical_cols].corr()
        fig, ax = plt.subplots(figsize=(12, 10))
        sns.heatmap(
            corr_data, 
            annot=True, 
            cmap="coolwarm", 
            ax=ax, 
            fmt=".2f", 
            linewidths=0.5,
            cbar_kws={"shrink": .8}
        )
        plt.title("Correlation Heatmap of Environmental Parameters")
        plt.tight_layout()
        st.pyplot(fig)
    
    except Exception as e:
        st.error(f"Error in correlation analysis: {e}")
    
    st.markdown("### Summary Statistics")
    try:
        summary_params = st.multiselect(
            "Select Parameters for Summary",
            options=numerical_cols,
            default=numerical_cols[:5]
        )
        
        summary_stats = dataset.groupby('Station_Name')[summary_params].agg(['mean', 'min', 'max', 'std']).round(2)
        summary_stats.columns = ['_'.join(col).strip() for col in summary_stats.columns.values]
        st.dataframe(summary_stats, use_container_width=True)
    
    except Exception as e:
        st.error(f"Error in summary statistics: {e}")
    
    st.markdown("### Parameter Distribution")
    try:
        boxplot_params = st.multiselect(
            "Select Parameters for Distribution Analysis",
            options=numerical_cols,
            default=numerical_cols[:3]
        )
        
        if boxplot_params:
            fig = px.box(
                dataset.melt(id_vars=['Station_Name'], value_vars=boxplot_params, var_name='Parameter', value_name='Value'), 
                x='Parameter', 
                y='Value', 
                color='Station_Name',
                title='Distribution of Parameters Across Stations'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    except Exception as e:
        st.error(f"Error in distribution analysis: {e}")

with tab5:
    st.markdown("<h2 class='sub-header'>GHI Prediction</h2>", unsafe_allow_html=True)
    
    if model is None:
        st.error("Model not loaded. Please ensure the model file is available.")
    else:
        st.markdown("### Enter Feature Values for Prediction")
        st.markdown("<div class='info-box'>Select a station to auto-fill values from the dataset, then adjust as needed.</div>", unsafe_allow_html=True)

        station_names = sorted(dataset['Station_Name'].unique().tolist())
        if len(station_names) != 43:
            st.warning(f"Dataset contains {len(station_names)} stations, but model expects 43. Predictions may be inaccurate unless station_names matches training data.")

        selected_station = st.selectbox("Select Station", options=station_names, index=0)

        station_data = dataset[dataset['Station_Name'] == selected_station].sort_values('Date', ascending=False).iloc[0]

        col1, col2 = st.columns(2)
        
        with col1:
            latitude = st.number_input("Latitude", min_value=16.0, max_value=33.0, 
                                     value=clamp(float(station_data['Latitude']), 16.0, 33.0), step=0.1)
            longitude = st.number_input("Longitude", min_value=34.0, max_value=56.0, 
                                      value=clamp(float(station_data['Longitude']), 34.0, 56.0), step=0.1)
            temperature = st.number_input("Air Temperature (°C)", min_value=-10.0, max_value=50.0, 
                                        value=clamp(float(station_data.get('Air Temperature (C°)', 25.0)), -10.0, 50.0), step=0.1)
            temp_uncertainty = st.number_input("Air Temp Uncertainty (°C)", min_value=0.0, max_value=5.0, 
                                             value=clamp(float(station_data.get('Air Temperature Uncertainty (C°)', 0.5)), 0.0, 5.0), step=0.1)
            wind_dir = st.number_input("Wind Direction at 3m (°N)", min_value=0.0, max_value=360.0, 
                                     value=clamp(float(station_data.get('Wind Direction at 3m (°N)', 0.0)), 0.0, 360.0), step=1.0)
            wind_dir_unc = st.number_input("Wind Dir Uncertainty (°N)", min_value=0.0, max_value=10.0, 
                                         value=clamp(float(station_data.get('Wind Direction at 3m Uncertainty (°N)', 4.0)), 0.0, 10.0), step=0.1)
            wind_speed = st.number_input("Wind Speed at 3m (m/s)", min_value=0.0, max_value=50.0, 
                                       value=clamp(float(station_data.get('Wind Speed at 3m (m/s)', 3.0)), 0.0, 50.0), step=0.1)
            wind_speed_unc = st.number_input("Wind Speed Uncertainty (m/s)", min_value=0.0, max_value=5.0, 
                                           value=clamp(float(station_data.get('Wind Speed at 3m Uncertainty (m/s)', 0.1)), 0.0, 5.0), step=0.1)
            wind_speed_std = st.number_input("Wind Speed Std Dev (m/s)", min_value=0.0, max_value=10.0, 
                                           value=clamp(float(station_data.get('Wind Speed at 3m (std dev) (m/s)', 1.5)), 0.0, 10.0), step=0.1)
            peak_wind = st.number_input("Peak Wind Speed at 3m (m/s)", min_value=0.0, max_value=50.0, 
                                      value=clamp(float(station_data.get('Peak Wind Speed at 3m (m/s)', 15.0)), 0.0, 50.0), step=0.1)
            peak_wind_unc = st.number_input("Peak Wind Uncertainty (m/s)", min_value=0.0, max_value=5.0, 
                                          value=clamp(float(station_data.get('Peak Wind Speed at 3m Uncertainty (m/s)', 0.1)), 0.0, 5.0), step=0.1)

        with col2:
            humidity = st.number_input("Relative Humidity (%)", min_value=0.0, max_value=100.0, 
                                     value=clamp(float(station_data.get('Relative Humidity (%)', 50.0)), 0.0, 100.0), step=1.0)
            humidity_unc = st.number_input("Humidity Uncertainty (%)", min_value=0.0, max_value=10.0, 
                                         value=clamp(float(station_data.get('Relative Humidity Uncertainty (%)', 3.0)), 0.0, 10.0), step=0.1)
            pressure = st.number_input("Barometric Pressure (hPa)", min_value=900.0, max_value=1100.0, 
                                     value=clamp(float(station_data.get('Barometric Pressure (mB (hPa equiv))', 1013.0)), 900.0, 1100.0), step=1.0)
            pressure_unc = st.number_input("Pressure Uncertainty (hPa)", min_value=0.0, max_value=10.0, 
                                         value=clamp(float(station_data.get('Barometric Pressure Uncertainty (mB (hPa equiv))', 4.6)), 0.0, 10.0), step=0.1)
            dhi = st.number_input("DHI (Wh/m2)", min_value=0.0, max_value=5000.0, 
                                value=clamp(float(station_data.get('DHI (Wh/m2)', 2000.0)), 0.0, 5000.0), step=10.0)
            dhi_unc = st.number_input("DHI Uncertainty (Wh/m2)", min_value=0.0, max_value=2000.0, 
                                    value=clamp(float(station_data.get('DHI Uncertainty (Wh/m2)', 500.0)), 0.0, 2000.0), step=10.0)
            dhi_std = st.number_input("Standard Deviation DHI (Wh/m2)", min_value=0.0, max_value=2000.0, 
                                    value=clamp(float(station_data.get('Standard Deviation DHI (Wh/m2)', 500.0)), 0.0, 2000.0), step=10.0)
            dni = st.number_input("DNI (Wh/m2)", min_value=0.0, max_value=10000.0, 
                                value=clamp(float(station_data.get('DNI (Wh/m2)', 5000.0)), 0.0, 10000.0), step=10.0)
            dni_unc = st.number_input("DNI Uncertainty (Wh/m2)", min_value=0.0, max_value=2000.0, 
                                    value=clamp(float(station_data.get('DNI Uncertainty (Wh/m2)', 1000.0)), 0.0, 2000.0), step=10.0)
            dni_std = st.number_input("Standard Deviation DNI (Wh/m2)", min_value=0.0, max_value=3000.0, 
                                    value=clamp(float(station_data.get('Standard Deviation DNI (Wh/m2)', 1000.0)), 0.0, 3000.0), step=10.0)
            ghi_unc = st.number_input("GHI UncertaintyEDD (Wh/m2)", min_value=0.0, max_value=2000.0, 
                                    value=clamp(float(station_data.get('GHI Uncertainty (Wh/m2)', 500.0)), 0.0, 2000.0), step=10.0)
            ghi_std = st.number_input("Standard Deviation GHI (Wh/m2)", min_value=0.0, max_value=2000.0, 
                                    value=clamp(float(station_data.get('Standard Deviation GHI (Wh/m2)', 500.0)), 0.0, 2000.0), step=10.0)

        if st.button("Predict GHI"):
            input_data = pd.DataFrame({
                'Latitude': [latitude],
                'Longitude': [longitude],
                'Air Temperature (C°)': [temperature],
                'Air Temperature Uncertainty (C°)': [temp_uncertainty],
                'Wind Direction at 3m (°N)': [wind_dir],
                'Wind Direction at 3m Uncertainty (°N)': [wind_dir_unc],
                'Wind Speed at 3m (m/s)': [wind_speed],
                'Wind Speed at 3m Uncertainty (m/s)': [wind_speed_unc],
                'Wind Speed at 3m (std dev) (m/s)': [wind_speed_std],
                'DHI (Wh/m2)': [dhi],
                'DHI Uncertainty (Wh/m2)': [dhi_unc],
                'Standard Deviation DHI (Wh/m2)': [dhi_std],
                'DNI (Wh/m2)': [dni],
                'DNI Uncertainty (Wh/m2)': [dni_unc],
                'Standard Deviation DNI (Wh/m2)': [dni_std],
                'GHI Uncertainty (Wh/m2)': [ghi_unc],
                'Standard Deviation GHI (Wh/m2)': [ghi_std],
                'Peak Wind Speed at 3m (m/s)': [peak_wind],
                'Peak Wind Speed at 3m Uncertainty (m/s)': [peak_wind_unc],
                'Relative Humidity (%)': [humidity],
                'Relative Humidity Uncertainty (%)': [humidity_unc],
                'Barometric Pressure (mB (hPa equiv))': [pressure],
                'Barometric Pressure Uncertainty (mB (hPa equiv))': [pressure_unc]
            })

            site_index = station_names.index(selected_station)
            for i in range(43):
                input_data[str(i)] = [1 if i == site_index else 0]

            try:
                prediction = model.predict(input_data)[0]
                st.success(f"Predicted GHI: **{prediction:.2f} Wh/m²**")
            except Exception as e:
                st.error(f"Error in prediction: {e}")

        st.markdown("### Model Information")
        st.write("This prediction uses a pre-trained model with one-hot encoded site data. Values are pre-filled from the latest dataset entry for the selected station.")